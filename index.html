<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chengfeng Zhao(赵乘风)</title>
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="styles_responsive.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
  <link href="https://fonts.cdnfonts.com/css/optima" rel="stylesheet">

  <script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.0.1/prism-bibtex.min.js"></script>
  <link rel="icon" type="image/png" href="images/android-chrome-512x512.png">

</head>

<body>
    <div class="container_onecolumn">
        <div class="container">
            <div class="item text">
              <p>
                <name>Chengfeng Zhao</name>
              </p>
              <p>
                I am currently a second-year master student at Visual & Data Intelligence Center of ShanghaiTech University, supervised by <a href="https://www.xu-lan.com/">Prof. Lan Xu</a>. 
                I am also fortunate to work closely with <a href="https://scholar.google.com/citations?user=R9L_AfQAAAAJ&hl=en">Prof. Jingyi Yu</a>, <a href="https://faculty.sist.shanghaitech.edu.cn/faculty/wangjingya/">Prof. Jingya Wang</a> and <a href="http://yuexinma.me/">Prof. Yuexin Ma</a>. 
                Before graduate study, I received my bachelor's degree from ShanghaiTech.
              </p>
              <p>
                My research interests include: 3D computer vision/graphics; Human-centric motion understanding; Multimodal learning.
              </p> 
              <p>
                <a href="mailto:zhaochf2022@shanghaitech.edu.cn"><i class="fa fa-paper-plane"></i>&nbsp&nbspEmail</a></a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=PKYWxA0AAAAJ&hl=en"><i class="ai ai-google-scholar ai-fw" style="font-size: 1.3em;position: relative; top:0.1em;margin-left: -0.3em;"></i>Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/AfterJourney00"><i class="fa fa-github"></i>&nbsp&nbspGithub</a> &nbsp/&nbsp
                <a href="https://orcid.org/0000-0002-8649-7470"><i class="ai ai-orcid-square ai-fw"></i></i>&nbsp&nbspORCID</a>
                
              </p>
            </div>
 
            <div class="item image">
              <img class="profile-photo" alt="profile photo" src="images/profile.jpg">
            </div>
          </div>
          
          
            <div class="item text2">
            <heading>Publications</heading>
            </div>
            <div class="container2">
                <div class="item image2">
                    <img src='images/imhoi.gif' width=180; height="auto">
                </div>
                <div class="item text2">
                <a href="https://afterjourney00.github.io/IM-HOI.github.io/">
                    <font color=#1772d0>  <papertitle>I'M HOI: Inertia-aware Monocular Capture of 3D Human-Object Interactions<sup>🔗</sup></papertitle></font>
                </a>
                <br>
                <strong>Chengfeng Zhao</strong>, 
                <a href="https://juzezhang.github.io/">Juze Zhang</a>,
                <a href="https://alt-js.github.io/">Jiashen Du</a>,
                <a href="https://cunkaixin.netlify.app/">Ziwei Shan</a>,
                Junye Wang,
                <a href=https://scholar.google.com/citations?user=R9L_AfQAAAAJ&hl=en>Jingyi Yu</a>,
                <a href="https://faculty.sist.shanghaitech.edu.cn/faculty/wangjingya/">Jingya Wang</a>,
                <a href="https://www.xu-lan.com/">Lan Xu</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024.</em>
                <br>
                <a href="https://afterjourney00.github.io/IM-HOI.github.io/">Project Page</a> /
                <a href="https://arxiv.org/abs/2312.08869">arXiv</a> /
                <a href="https://github.com/AfterJourney00/IMHD-Dataset">Code</a> /
                <a href="https://forms.gle/3MDh3b4szhFwcYa26">Dataset</a> /
                <a href="https://www.youtube.com/watch?v=MdG00uakBa8">Video</a> /
                <button id="bib_button" class="link", onclick="showBib('imhoi_bib')">BibTex</button>
                <div id='imhoi_bib' hidden>
                <pre><code>@InProceedings{zhao2024imhoi,
  author    = {Zhao, Chengfeng and Zhang, Juze and Du, Jiashen and Shan, Ziwei and Wang, Junye and Yu, Jingyi and Wang, Jingya and Xu, Lan},
  title     = {I'M HOI: Inertia-aware Monocular Capture of 3D Human-Object Interactions},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2024},
  pages     = {729-741}
}</code></pre>
                </div>
            </div>
          </div>

        <hr>

          <div class="container2">
            <div class="item image2">
              <img src='images/hoim3.gif' width=180; height="auto">
            </div>
            <div class="item text2">
              <a href="https://juzezhang.github.io/HOIM3_ProjectPage/">
                <font color=#1772d0>  <papertitle>HOI-M<sup>3</sup>: Capture Multiple Humans and Objects Interaction within Contextual Environment<sup>🔗</sup></papertitle></font>
                </a>
                <br>
                <a href="https://juzezhang.github.io/">Juze Zhang*</a>,
                <a href="https://zhanglele12138.github.io/">Jingyan Zhang*</a>,
                Zining Song,
                Zhanhe Shi,
                <strong>Chengfeng Zhao</strong>,
                <a href="https://shiye21.github.io/">Ye Shi</a>,
                <a href=https://scholar.google.com/citations?user=R9L_AfQAAAAJ&hl=en>Jingyi Yu</a>,
                <a href="https://www.xu-lan.com/">Lan Xu</a>,
                <a href="https://faculty.sist.shanghaitech.edu.cn/faculty/wangjingya/">Jingya Wang</a>
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024.</em>
                <br>
                <a href="https://juzezhang.github.io/HOIM3_ProjectPage/">Project Page</a> /
                <a href="https://arxiv.org/abs/2404.00299">arXiv</a> /
                <a href="https://drive.google.com/drive/folders/1bT7J0XnbUx5goixgJRWJxpycOFffpwOc?usp=sharing">Dataset</a> /
                <a href="https://www.youtube.com/watch?v=Fq6iqoXC99A">Video</a> /
                <button id="bib_button" class="link", onclick="showBib('hoim3_bib')">BibTex</button>
                <div id='hoim3_bib' hidden>
                <pre><code>@InProceedings{Zhang_2024_CVPR,
  author    = {Zhang, Juze and Zhang, Jingyan and Song, Zining and Shi, Zhanhe and Zhao, Chengfeng and Shi, Ye and Yu, Jingyi and Xu, Lan and Wang, Jingya},
  title     = {HOI-M{\textasciicircum}3: Capture Multiple Humans and Objects Interaction within Contextual Environment},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2024},
  pages     = {516-526}
}</code></pre>
            </div>
        </div>
      </div>

      <hr>

      <div class="container2">
        <div class="item image2">
          <img src='images/livehps.gif' width=180; height="auto">
        </div>
        <div class="item text2">
          <a href="https://arxiv.org/abs/2402.17171">
            <font color=#1772d0>  <papertitle>LiveHPS: LiDAR-based Scene-level Human Pose and Shape Estimation in Free Environment<sup>🔗</sup></papertitle></font>
          </a>
          <br>
          <a href=https://ren-ym.github.io/>Yiming Ren</a>, 
          Xiao Han,
          <strong>Chengfeng Zhao</strong>,
          <a href="https://faculty.sist.shanghaitech.edu.cn/faculty/wangjingya/">Jingya Wang</a>,
          <a href="https://www.xu-lan.com/">Lan Xu</a>,
          <a href=https://scholar.google.com/citations?user=R9L_AfQAAAAJ&hl=en>Jingyi Yu</a>,
          <a href=http://yuexinma.me/>Yuexin Ma</a>
          <br>
          <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024.</em>
          <br>
          <a href="https://arxiv.org/abs/2402.17171">arXiv</a> /
          <button id="bib_button" class="link", onclick="showBib('livehps_bib')">BibTex</button>
          <div id='livehps_bib' hidden>
          <pre><code>@InProceedings{Ren_2024_CVPR,
  author    = {Ren, Yiming and Han, Xiao and Zhao, Chengfeng and Wang, Jingya and Xu, Lan and Yu, Jingyi and Ma, Yuexin},
  title     = {LiveHPS: LiDAR-based Scene-level Human Pose and Shape Estimation in Free Environment},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2024},
  pages     = {1281-1291}
}</code></pre>
        </div>
    </div>
  </div>

<hr>

<div class="container2">
<div class="item image2">
  <img src='images/lip.gif' width=180; height="auto">
</div>
<div class="item text2">
  <a href="https://4dvlab.github.io/project_page/LIPD.html">
    <font color=#1772d0>  <papertitle>LiDAR-aid Inertial Poser: Large-scale Human Motion Capture by Sparse Inertial and LiDAR Sensors<sup>🔗</sup></papertitle></font>
  <br>
  <a href=https://ren-ym.github.io/>Yiming Ren*</a>, 
  <strong>Chengfeng Zhao*</strong>,
  <a href="https://virtualhumans.mpi-inf.mpg.de/people/He.html">Yannan He</a>,
  <a href="https://coralemon.github.io/">Peishan Cong</a>,
  <a href="https://tr3e.github.io/">Han Liang</a>,
  <a href=https://scholar.google.com/citations?user=R9L_AfQAAAAJ&hl=en>Jingyi Yu</a>,
  <a href="https://www.xu-lan.com/">Lan Xu</a>,
  <a href=http://yuexinma.me/>Yuexin Ma</a>
  <br>
  <em>IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE VR), 2023.</em>
  <br>
  <a href="https://4dvlab.github.io/project_page/LIPD.html">Project Page</a>
  / <a href="https://arxiv.org/abs/2205.15410">arXiv</a>
  / <a href="https://github.com/4DVLab/LIP">Code</a>
  / <a href="https://drive.google.com/file/d/1SVO77FWFUOtC-Et2sdlgAdiNQWzgzxt0/view?usp=sharing">Dataset</a>
  / <a href="https://www.youtube.com/watch?v=ao9eTGPQT6k">Video</a>
  / <button id="bib_button" class="link", onclick="showBib('lip_bib')">BibTex</button>
  <div id='lip_bib' hidden>
  <pre><code>@article{ren2023lidar,
  title={Lidar-aid inertial poser: Large-scale human motion capture by sparse inertial and lidar sensors},
  author={Ren, Yiming and Zhao, Chengfeng and He, Yannan and Cong, Peishan and Liang, Han and Yu, Jingyi and Xu, Lan and Ma, Yuexin},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  volume={29},
  number={5},
  pages={2337--2347},
  year={2023},
  publisher={IEEE}
}</code></pre>
  </div>
  </div>
</div>

<hr>

<div class="container2">
<div class="item image2">
  <img src='images/hybridcap.gif' width=180; height="auto">
</div>
<div class="item text2">
  <a href="https://arxiv.org/abs/2203.09287">
    <font color=#1772d0>  <papertitle>HybridCap: Inertia-aid Monocular Capture of Challenging Human Motions<sup>🔗</sup></papertitle></font>
  </a>
  <br>
  <a href="https://tr3e.github.io/">Han Liang</a>,
  <a href="https://virtualhumans.mpi-inf.mpg.de/people/He.html">Yannan He</a>,
  <strong>Chengfeng Zhao</strong>, 
  Mutian Li,
  <a href="https://faculty.sist.shanghaitech.edu.cn/faculty/wangjingya/">Jingya Wang</a>,
  <a href=https://scholar.google.com/citations?user=R9L_AfQAAAAJ&hl=en>Jingyi Yu</a>,
  <a href="https://www.xu-lan.com/">Lan Xu</a>
  <br>
  <em>The 37th AAAI Conference on Artificial Intelligence (AAAI), 2023.</em>
  <br>
  <a href="https://arxiv.org/abs/2203.09287">arXiv</a> /
  <a href="https://www.youtube.com/watch?v=fV4IRTUdSws">Video</a> / 
  <button id="bib_button" class="link", onclick="showBib('hybridcap_bib')">BibTex</button>
  <div id='hybridcap_bib' hidden>           
    <pre><code>@inproceedings{liang2023hybridcap,
  title={Hybridcap: Inertia-aid monocular capture of challenging human motions},
  author={Liang, Han and He, Yannan and Zhao, Chengfeng and Li, Mutian and Wang, Jingya and Yu, Jingyi and Xu, Lan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={2},
  pages={1539--1548},
  year={2023}
}</code></pre>
  </div>
</div>
</div>

<div class="item text2">
  <heading>Hornors and Awards</heading>
  <ul>
    <li>Graduate:</li>
    <ul>
      <li>2024.03 <b>“Outstanding Teaching Assistant”</b></li>
      <li>2023.12 <b>“Merit Student</b></li>
    </ul>
    <li>Undergraduate:</li>
    <ul>
      <li>2022.06 <b>“Outstanding Graduate of Shanghai”</b></li>
      <li>2022.06 <b>“Outstanding Graduate of ShanghaiTech University”</b></li>
      <li>2021.12 <b>“Outstanding Student Leader”</b></li>
      <li>2021.12 <b>“Outstanding Student”</b></li>
      <li>2020.12 <b>“Merit Student”</b></li>
    </ul>
  </ul>
</div>

<div class="item text2">
  <heading>Internships</heading>
</div>
<div class="container2">
  <div class="item image2">
      <img src='images/SenseTime_logo.png' width=180; height="auto">
  </div>
  <div class="item text2">
  <b>Computer Vision Researcher</b>
  <br>
  SenseTime, Shanghai, China
  <br>
  Mentor: <a href="https://scholar.google.com/citations?user=F5rVlz0AAAAJ&hl=en">Cheng Li</a>
  <br>
  2021.06 - 2021.09
  </div>
</div>

<div class="item text2">
  <heading>Invited Talks</heading>
</div>

<div class="item text2">
  <heading>Teaching Assistants</heading>
  <ul>
    <li>2023 Fall & 2022 Fall, <b>CS280: Deep Learning</b>, ShanghaiTech University</li>
    <li>2022 Spring, <b>CS100: Introduction to Programming</b>, ShanghaiTech University</li>
    <li>2021 Fall, <b>CS130: Operating Systems</b>, ShanghaiTech University</li>
    <li>2021 Spring, <b>SI100B: Introduction to Information Science and Technology</b>, ShanghaiTech University</li>
  </ul>
</div>

<div class="item text2">
  <heading>Educations</heading>
</div>
<div class="container2">
  <div class="item image2">
      <img src='images/shanghaitech.png' width=180; height="auto">
  </div>
  <div class="item text2">
  <b>Master</b>
  <br>
  ShanghaiTech University, Shanghai, China
  <br>
  2022.09 - now
  </div>
</div>

<div class="container2">
  <div class="item image2">
      <img src='images/shanghaitech.png' width=180; height="auto">
  </div>
  <div class="item text2">
  <b>Bachelor</b>
  <br>
  ShanghaiTech University, Shanghai, China
  <br>
  2018.09 - 2022.06
  </div>
</div>

<div class="container2">
  <div class="item image2">
      <img src='images/nsfz.jpg' width=180; height="auto">
  </div>
  <div class="item text2">
  <b>High school</b>
  <br>
  High School Affiliated to Nanjing Normal University, Nanjing, China
  <br>
  2015.09 - 2018.06
  </div>
</div>

<script type="text/javascript" src="show_bib.js"></script>
</body>
</html>